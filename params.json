{"name":"Breacon","tagline":"Breaking the Concurrency: Randomizing the Thread Scheduler to unravel hidden bugs","body":"Problem Statement\r\n\r\nModern web and distributed applications heavily rely on concurrent execution. As usage of multi-core \r\n\r\nprocessors gain momentum, client side programs are also switching to multiple threads in their code. However, even \r\n\r\nfor skilled developers, creating multithreaded software is a challenge. Concurrency issues such as deadlocks and \r\n\r\ndata races are often tough to fix without being able to reproduce them. In a multi-threaded concurrent program, the \r\n\r\nnumber of possible interleavings is enormous - exponential to the length of the program and the number of threads \r\n\r\n[1]. These interleavings depend on the context switches that happened during the run which are very difficult to \r\n\r\npredict; thus, the probability of reproducing a concurrent failure is extremely low. Stress testing methods such as \r\n\r\nrepeatedly executing the program for different payloads with the hope of finding a bug is not efficient because tests \r\n\r\nthat are independent of I/O latency and network usage will usually lead to the same interleaving. We believe that an \r\n\r\neffective concurrency fuzzer should have the following characteristics:\r\n\r\n1. Accuracy - Find valid bugs with particular emphasis on minimizing false positives.\r\n\r\n2. Replay Support – A replay algorithm to support reproducibility.\r\n\r\n3. Coverage – Test the entire problem space and prove the absence of faults.\r\n\r\n4. Extensibility - Plugin based architecture to support enhancements.\r\n\r\nWe did a study of few existing concurrency testing techniques [2] [3] [4] [5] and found that none of them \r\n\r\nwere calibrated to support the aforementioned characteristics. As part of the first phase of our research we want to \r\n\r\ndevelop a fuzzer that is capable of finding concurrency bugs with high probability and tries to achieve a balance \r\n\r\nbetween the first three characteristics listed above. If time permits, for the second phase we intend to develop an \r\n\r\nextensible framework for the tool to support customizations.  \r\n\r\nOur Idea\r\n\r\nWe plan to combine different techniques to create a new method of concurrency bug detection. Fuzz testing \r\n\r\nhas proven itself to be a powerful means of detecting bugs. This type of testing provides an application with random \r\n\r\ninput and records the application’s response. Hanging and crashing signify that the application has failed the test. We \r\n\r\nwill build upon these ideas by randomly scheduling threads to uncover concurrency bugs. However, these bugs often \r\n\r\noccur infrequently, and we can reduce the required time to find bugs by combining the random scheduling with \r\n\r\nheuristics. Common concurrency bugs including data races and deadlocks are normally caused by the improper use of \r\n\r\nsynchronization primitives or the lack thereof. Without these primitives, sequences of instructions may be executed \r\n\r\nin any order. Synchronization reduces the number of possible sequences, and when properly used, eliminates all of \r\n\r\nthe error-causing sequences. This knowledge may be paired with fuzz testing to create random sequences that are \r\n\r\nmost likely to result in exhibiting bugs if they exist.\r\n\r\nOur approach will scan the binaries of its target applications to find critical points for concurrency bugs. \r\n\r\nThese points include obtaining and releasing locks, as well as, accessing shared memory. If these points may be \r\n\r\nexecuted in any order without changing the output, then there are no concurrency bugs. Our approach also involves \r\n\r\nadding to the fuzz testing framework to check the output of programs in addition to checking that they do not crash \r\n\r\nor hang. We selected this approach, because it allows for our tool to learn about applications without requiring \r\n\r\nsource code or developer intervention.\r\n\r\nWe plan to utilize software debugger’s capabilities of stopping program execution to place stalls in threads. \r\n\r\nBy inserting breakpoints throughout the code, we can stop and start threads in such a way that allows us to control \r\n\r\nthe sequencing of instructions. Programs will run multiple times in the debugger with the breakpoints set in different \r\n\r\nplaces to test different sequences. If one sequence fails, our tool will record the results and the breakpoints used. \r\n\r\nThis allows the sequence to be recreated and the programmer to understand what went wrong. The tool will \r\n\r\nautomate running tests to further simplify the task of finding bugs.\r\n\r\nImplementation Plan \r\n\r\nWe are currently scheduling our project to be completed in eight full weeks after our initial preparation \r\n\r\nweek. This week, week zero, is devoted to finding and reading related research and gaining a high-level insight into \r\n\r\ndebuggers and program analysis. After this week, we will be able to plan the details of our testing tool and begin our \r\n\r\nimplementation. \r\n\r\nWeeks one and two (12. October - 25. October) are proposed for developing the program analysis portion \r\n\r\nof the tool. We will build an application that can load an executable binary and locate the critical points for \r\n\r\nconcurrency. These points will be stored in a list with their accompanying type. We plan to look into resources \r\n\r\nregarding compiler construction and dynamic instrumentation to design and develop this portion of the tool.\r\n\r\nWeeks three and four (26. October - 8. November) will be used for integrating the debugger into our tool. \r\n\r\nWe will also build our central testing algorithm in this stage. After completing program analysis, the tool will fork a \r\n\r\nnew process and run the debugger. Through inter-process communication, the parent process will operate the \r\n\r\ndebugger by instructing it to run the binary with the appropriate breakpoints. The tool will time the execution of the \r\n\r\ndebugger and monitor the output of the application being tested.\r\n\r\nWeek five and the first half of week six (9. November - 19. November) will be our testing phase. We will \r\n\r\nrun our tool on a variety of concurrent applications, some of which will have known concurrency bugs. If our tool \r\n\r\nfunctions properly, it should find the known bugs. We hope to discover some unknown concurrency bugs as well.\r\n\r\nThe second half of week six and week seven (20. November - 29. November) will be used for performing \r\n\r\nour analysis of our testing and the tool in general. During this time we will write our final report on the project. \r\n\r\nWeek eight is slack time, which will be reserved in the case of exceptional circumstances or unforeseen delays. We \r\n\r\nwill finish the project by 28. November.\r\n\r\nEvaluation Criteria\r\n\r\nThe concurrency bug detection algorithm and replay algorithm will form the core of our tool. The efficacy \r\n\r\nof heuristics and models applied in the algorithm implementation would decide if our concurrency failure detection \r\n\r\ntechnique performs better than existing testing approaches. During the testing phase, we plan to run our fuzzer on \r\n\r\nvariety of multi-threaded applications. It is important that the fuzzer provides code coverage guarantee, discovers \r\n\r\nvalid bugs and reduces the likelihood of false positives.\r\n\r\nReferences\r\n\r\n[1] O. Edelstein, E. Farchi, Y. Nir, G. Ratsaby, S. Ur, “Multithreaded Java program test generation”,pp1,  2002.\r\n\r\n[2] Sebastian Burckhardt, Pravesh Kothari, Madanlal Musuvathi “A Randomized Scheduler with Probabilistic   \r\n\r\nGuarantees of Finding Bugs”, March. 2010.\r\n\r\n\r\n[3] Evgeny Vainer, Amiram Yehudai, “Controlling Concurrent Behavior while Testing Multithreaded Software”,  \r\n\r\n2013.\r\n\r\n[4] Pallavi Joshi, Mayur Naik, Chang-Seo Park, and Koushik Sen, “CalFuzzer: An Extensible Active Testing\r\n\r\nFramework for Concurrent Programs”, 2009\r\n\r\n[5] Qingzhou Luo, Sai Zhang, Jianjun Zhao, and Min Hu, “A Lightweight and Portable Approach to Making\r\n\r\nConcurrent Failures Reproducible”, 201","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}